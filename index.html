<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Practicalmachinelearning by schigrinov</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Practicalmachinelearning</h1>
      <h2 class="project-tagline"></h2>
      <a href="https://github.com/schigrinov/PracticalMachineLearning" class="btn">View on GitHub</a>
      <a href="https://github.com/schigrinov/PracticalMachineLearning/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/schigrinov/PracticalMachineLearning/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <p></p>

<p></p>

<p>

</p>

<p></p>

<p></p>

<p></p>Machine Learning Assesment



<p>
</p>







code{white-space: pre;}

<p></p>




  pre:not([class]) {
    background-color: white;
  }




<p></p>

<p></p>


.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}


<div>


<div id="header">
<h1>
<a id="machine-learning-assesment" class="anchor" href="#machine-learning-assesment" aria-hidden="true"><span class="octicon octicon-link"></span></a>Machine Learning Assesment</h1>
<h4>
<a id="sergey-chigrinov" class="anchor" href="#sergey-chigrinov" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Sergey Chigrinov</em>
</h4>
<h4>
<a id="december-21-2015" class="anchor" href="#december-21-2015" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>December 21, 2015</em>
</h4>
</div>

<p>In this work we will try to predict activity quality from activity monitors. For the analysis we’ll use the Weight Lifting Exercise Dataset, from the following paper: Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human ’13) . Stuttgart, Germany: ACM SIGCHI, 2013.</p>

<pre><code>#knitr::opts_chunk$set(cache=TRUE)
knitr::opts_chunk$set(warning=FALSE, message=FALSE, fig.path='Figs/')
set.seed(1)</code></pre>

<pre><code>setwd("~/Sergey/Coursera/DataScience/Mashine learning/PeerAssessment")
library(tree)
library(caret)
library(randomForest)</code></pre>

<pre><code>   trainData &lt;- read.csv("pml-training.csv",na.strings=c("", "NA", "NULL"))  
   validationData &lt;- read.csv("pml-testing.csv",na.strings=c("", "NA", "NULL"))</code></pre>

<div id="preprocessing">
<h2>
<a id="preprocessing" class="anchor" href="#preprocessing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preprocessing</h2>
<pre><code>dim(trainData)</code></pre>
<pre><code>## [1] 19622   160</code></pre>
<p>There are 19622 obs. of 160 variables. A lot of values of some variables are missing, and there are some unnecessary columns, so we need to clean our data.</p>
<pre><code>goodvar &lt;- sapply(trainData, function(x) {sum(is.na(x))})==0
trainData &lt;- trainData[,goodvar]
trainData &lt;- trainData[, -1:-6]
dim(trainData)</code></pre>
<pre><code>## [1] 19622    54</code></pre>
<p>The variable we need to predict is train$classe.</p>
<pre><code>levels(trainData$classe)</code></pre>
<pre><code>## [1] "A" "B" "C" "D" "E"</code></pre>
<p>The “classe” variable has 5 levels.</p>
<p>To perform cross-validation testing we need to split the initial data set into training and testing sets.</p>
<pre><code>inTrain &lt;- createDataPartition(trainData$classe,p=0.75, list=FALSE)
training &lt;- trainData[inTrain,]
testing &lt;- trainData[-inTrain,]</code></pre>
</div>

<div id="model-fitting">
<h2>
<a id="model-fitting" class="anchor" href="#model-fitting" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model fitting</h2>
<p>Since the objective is classification, we’ll try to use Classification Tree and Random Forest algorythms. For the classification we’ll use “tree” package - seems like it produces better results that “caret” package, and works faster. It could be because of some defaults or due to implementation.</p>
<p>Classification tree:</p>
<pre><code>fitTree &lt;- tree(classe ~ ., data=training)
testPredTree=predict(fitTree,training, type = "class")
trainConfusion &lt;- confusionMatrix(testPredTree, training$classe)
testPredTree=predict(fitTree,testing, type = "class")
testConfusion &lt;- confusionMatrix(testPredTree, testing$classe)
trainConfusion$overall</code></pre>
<pre><code>##       Accuracy          Kappa  AccuracyLower  AccuracyUpper   AccuracyNull 
##   7.153825e-01   6.413461e-01   7.080165e-01   7.226633e-01   2.843457e-01 
## AccuracyPValue  McnemarPValue 
##   0.000000e+00  9.583005e-269</code></pre>
<pre><code>accTree &lt;- testConfusion$overall[1]
testConfusion$overall</code></pre>
<pre><code>##       Accuracy          Kappa  AccuracyLower  AccuracyUpper   AccuracyNull 
##   7.255302e-01   6.540704e-01   7.128069e-01   7.379845e-01   2.844617e-01 
## AccuracyPValue  McnemarPValue 
##   0.000000e+00   1.319750e-73</code></pre>
<pre><code>plot(fitTree)
text(fitTree,pretty=0, cex =.6)</code></pre>
<p><img title alt width="672"></p>
<pre><code>testConfusion$table</code></pre>
<pre><code>##           Reference
## Prediction    A    B    C    D    E
##          A 1198   97    3   14   22
##          B   61  580   45   83   99
##          C   13   33  712  177   48
##          D  103  200   94  516  180
##          E   20   39    1   14  552</code></pre>
<p>We have <code>27.45</code>% of incorrect results for test set for the Classification Tree. Our out of sample error is not satisfactory.</p>
<p>We’ll try to improve the result by using Random Forest algorythm. Let’s grow 100 trees for our random forest. Randon forest:</p>
<pre><code>#by default ntree=500, but for our task it should be enough to use ntree=100
fitForest=randomForest(classe~.,data=training,ntree=100)</code></pre>
<p>Variable Importance (first 20 var.)</p>
<pre><code>varImpPlot(fitForest, n.var=20)</code></pre>
<p><img title alt width="672"></p>
<pre><code>testPredForest=predict(fitForest,training, type = "class")
trainConfusion &lt;- confusionMatrix(testPredForest, training$classe)
testPredForest=predict(fitForest,testing, type = "class")
testConfusion &lt;- confusionMatrix(testPredForest, testing$classe)
trainConfusion$overall</code></pre>
<pre><code>##       Accuracy          Kappa  AccuracyLower  AccuracyUpper   AccuracyNull 
##      1.0000000      1.0000000      0.9997494      1.0000000      0.2843457 
## AccuracyPValue  McnemarPValue 
##      0.0000000            NaN</code></pre>
<pre><code>accForest &lt;- testConfusion$overall[1]
testConfusion$overall</code></pre>
<pre><code>##       Accuracy          Kappa  AccuracyLower  AccuracyUpper   AccuracyNull 
##      0.9985726      0.9981944      0.9970612      0.9994259      0.2844617 
## AccuracyPValue  McnemarPValue 
##      0.0000000            NaN</code></pre>
<pre><code>testConfusion$table</code></pre>
<pre><code>##           Reference
## Prediction    A    B    C    D    E
##          A 1395    2    0    0    0
##          B    0  947    1    0    0
##          C    0    0  854    4    0
##          D    0    0    0  800    0
##          E    0    0    0    0  901</code></pre>
<p>The accuracy of the algorythm on the test set is 99.8572594% - much better than the result of the classification tree.</p>
</div>

<div id="final-model-and-result">
<h2>
<a id="final-model-and-result" class="anchor" href="#final-model-and-result" aria-hidden="true"><span class="octicon octicon-link"></span></a>Final model and result</h2>
<pre><code>finalFitForest=randomForest(classe~.,data=trainData,ntree=100)
answers &lt;- predict(finalFitForest,validationData, type = "class")
answers</code></pre>
<pre><code>##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
##  B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
## Levels: A B C D E</code></pre>
<p>Write the answers to files:</p>
<pre><code>setwd("~/Sergey/Coursera/DataScience/Mashine learning/PeerAssessment/Submission")
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(answers)</code></pre>
</div>

<p></p>
</div>







<p>
</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/schigrinov/PracticalMachineLearning">Practicalmachinelearning</a> is maintained by <a href="https://github.com/schigrinov">schigrinov</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
